{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pybedtools import BedTool as bedtools\n",
    "# default bedtools column names: chrom, start, stop, name, score and strand.\n",
    "\n",
    "pd.options.mode.chained_assignment = 'warn'  # default='warn'; set to \"None\" to ignore warnings\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 20  # default is 20\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "class Global_Vars(object):\n",
    "    '''Here, we:\n",
    "    1. load the rnase df, and get gene_ofInterest_info (goi).\n",
    "    2. get the region of interest (roi), dhss with signal in roi (df_dhss),\n",
    "    add known enhancers to the df (also add \"has_known enhancers\" col).\n",
    "    3. get the df with tfs (from cellnet) with their pcc and zscore info (df_tfs).\n",
    "    \n",
    "    Note that we do not transform data in any way (eg. by taking log of tpm)\n",
    "    \n",
    "    To do:\n",
    "    1. add known enhancers to df_roi_dhss (also add \"has_known enhancers\" col),\n",
    "    3. get random df_dhss for this gene, - only take_this_many_top_dhs_fts are selcted\n",
    "    4. get random df_tfs for this gene.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, args):  # note this takes in new_output_dir as well in .py scripts\n",
    "        ######################################################\n",
    "        ###### set the logging handlers and params ######\n",
    "        formatter = logging.Formatter('%(asctime)s: %(name)-12s: %(levelname)-8s: %(message)s')\n",
    "\n",
    "        file_handler = logging.FileHandler(os.path.join(args.outputDir, args.gene.upper() + '.log'))\n",
    "        file_handler.setLevel(logging.DEBUG)\n",
    "        file_handler.setFormatter(formatter)\n",
    "\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        stream_handler.setLevel(logging.INFO)\n",
    "        stream_handler.setFormatter(formatter)\n",
    "\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        self.logger.addHandler(file_handler)\n",
    "        self.logger.addHandler(stream_handler)\n",
    "\n",
    "        self.logger.info(\"Setting up the DNase-seq dataframe and gene expression vector..\")\n",
    "        ######################################################\n",
    "        ###### set up the basic args variables ######\n",
    "\n",
    "        self.gene_ofInterest = args.gene.upper()\n",
    "        self.dist_lim = args.distance  # in kb\n",
    "        self.use_tad_info = args.use_tad_info\n",
    "        self.pcc_lowerlimit_to_filter_dhss = args.pcc_lowerlimit_to_filter_dhss\n",
    "        self.take_log2_tpm = args.take_log2_tpm\n",
    "        self.filter_tfs_by = args.filter_tfs_by\n",
    "        self.lowerlimit_to_filter_tfs = args.lowerlimit_to_filter_tfs\n",
    "        self.take_this_many_top_fts = args.take_this_many_top_fts  # all dhss/tfs will already be filtered by pcc(or zscore)\n",
    "        self.init_wts_type = args.init_wts_type\n",
    "        self.inputDir = os.path.abspath(\"../../Input_files\")\n",
    "        self.outputDir = args.outputDir  # generated using  get_output_dir from helper_functions\n",
    "        self.use_random_DHSs = args.use_random_DHSs\n",
    "        self.use_random_TFs = args.use_random_TFs\n",
    "        ######################################################\n",
    "        ###### read and set up the basic data frames ######\n",
    "        # self.csv_enhancer_tss = os.path.join(self.inputDir, \"enhancer_tss_associations.bed\")\n",
    "        \n",
    "        self.csv_dhss = os.path.join(self.inputDir, \"roadmap.dnase_imputed.merged_by_samplesAndBedTools.pval.signal.txt\")\n",
    "        self.csv_rnase = os.path.join(self.inputDir, \"roadmap.rnase_imputed.LogRPKM.signal.mergedWTADlocs.txt\")\n",
    "        self.csv_cn = os.path.join(self.inputDir, \"Human_Big_GRN_032014.csv\")\n",
    "\n",
    "        '''Get the goi, roi, df_roi_dhss and df_tfs objects\n",
    "        (See description above __init__().)'''\n",
    "        df_rnase = pd.read_csv(self.csv_rnase, sep=\"\\t\", index_col=[\"geneName\", \"loc\", \"TAD_loc\"])\n",
    "        self.goi = self.get_gene_ofInterest_info(df_rnase)\n",
    "        self.roi = self.get_roi(self.goi)  # need self.goi to get gene tss loc from goi.index\n",
    "        \n",
    "        df_dhss = self.get_df_dhss(self.roi)\n",
    "        self.df_dhss = self.filter_ftsIn_multiIndexed_df_by_pcc(df_dhss)\n",
    "        if (self.use_random_DHSs):\n",
    "            self.df_dhss = self.get_random_dhs_df()  # dhss could be from different chromosomes\n",
    "        \n",
    "        df_tfs = self.get_df_tfs(df_rnase)\n",
    "        self.df_tfs = self.filter_tf_fts(df_tfs)\n",
    "        if (self.use_random_TFs):\n",
    "            self.df_tfs = self.get_random_tfs_df()\n",
    "        self.logger.info(\"Done. Setting up the training and testing split..\")\n",
    "        ################## end of __init__() ######################\n",
    "        \n",
    "        \n",
    "    '''Load the rnase df, get gene_ofInterest_info (goi)'''\n",
    "    def get_gene_ofInterest_info(self, df_rnase):\n",
    "        '''Note: The output \"self.gene_ofInterest_info.name\" is a tuple of form: \n",
    "        (geneName, loc, tad_loc). The output will be abbreviated as \"goi\" hence-forth.\n",
    "        The gex values are logged if self.take_log2_tpm == True.'''\n",
    "        df_gene_ofInterest = df_rnase.iloc[df_rnase.index.get_level_values(\"geneName\") == self.gene_ofInterest]\n",
    "        gene_ofInterest_info = df_gene_ofInterest.iloc[0] \n",
    "        return gene_ofInterest_info\n",
    "    \n",
    "    '''Get chromosomal region of interest(or roi).'''\n",
    "    def get_roi(self, gene_ofInterest_info):\n",
    "        tss_ss_es = re.split(\":|-\", gene_ofInterest_info.name[1])[1:]\n",
    "        tss_pos = int(sum([int(x) for x in tss_ss_es])/2)\n",
    "\n",
    "        tad_chr_ss_es = re.split(\":|-\", gene_ofInterest_info.name[2])\n",
    "        roi_chr = tad_chr_ss_es[0]\n",
    "        tad_ss, tad_es = [int(x) for x in tad_chr_ss_es[1:]]\n",
    "\n",
    "        roi_upstream = max(tss_pos - (self.dist_lim*1000), tad_ss)\n",
    "        roi_downstream = min(tss_pos + (self.dist_lim*1000), tad_es)\n",
    "        \n",
    "        return roi_chr, roi_upstream, roi_downstream\n",
    "    \n",
    "    '''Given roi loc, get only those dhss that overlap it. \n",
    "    This function takes a few seconds to finish.'''\n",
    "    def get_df_dhss(self, roi_loc):\n",
    "        roi_chr, roi_upstream, roi_downstream = roi_loc\n",
    "        bed_roi = bedtools(\"{}\\t{}\\t{}\".format(roi_chr, roi_upstream, roi_downstream), from_string=True)\n",
    "\n",
    "        '''Get dhs locs only dataframe/bed object to do bedintersect with roi.'''\n",
    "        df_dhss = pd.read_csv(self.csv_dhss, sep=\"\\t\", index_col=\"loc\")  # df_dhss is the original dhs with loc of chr:ss-es as index and sample values as cols across\n",
    "        dhs_locs = [re.split(\":|-\", x) for x in df_dhss.index.tolist()]\n",
    "        dhs_locs = [[x[0],int(x[1]),int(x[2])] for x in dhs_locs]\n",
    "        df_dhs_locs = pd.DataFrame.from_records(dhs_locs, columns=[\"chrom\", \"ss\", \"es\"])\n",
    "        bed_dhs_locs = bedtools.from_dataframe(df_dhs_locs)\n",
    "\n",
    "        '''Get roi_dhss_locs - i.e. a list with elements chr:ss-es corresponding to dhs sites'''\n",
    "        bed_roi_dhss_locs = bed_roi.intersect(bed_dhs_locs, wb=True)\n",
    "        df_roi_dhss_locs = pd.read_table(bed_roi_dhss_locs.fn, names=[\"chr_int\", \"ss_int\", \"es_int\", \"chr_dhs\", \"ss_dhs\", \"es_dhs\"])\n",
    "        df_roi_dhss_locs = df_roi_dhss_locs[[\"chr_dhs\", \"ss_dhs\", \"es_dhs\"]]\n",
    "        roi_dhss_locs = [\"{}:{}-{}\".format(x[0],str(x[1]),str(x[2])) for x in \n",
    "                         zip(df_roi_dhss_locs[\"chr_dhs\"],df_roi_dhss_locs[\"ss_dhs\"], df_roi_dhss_locs[\"es_dhs\"])]\n",
    "        df_roi_dhss = df_dhss[df_dhss.index.isin(roi_dhss_locs)]\n",
    "        \n",
    "        '''Add PCC(dhs, goi) to the index'''\n",
    "        pccs = [] \n",
    "        for ix in range(0, df_roi_dhss.shape[0]):\n",
    "            pccs.append(np.corrcoef(df_roi_dhss.iloc[ix], self.goi)[0,1])\n",
    "        df_roi_dhss[\"pcc\"] = pccs\n",
    "        df_roi_dhss = df_roi_dhss.set_index(\"pcc\", append=True)\n",
    "\n",
    "        return df_roi_dhss\n",
    "    \n",
    "    '''Filter a multilevel indexed df by its pcc index value in 2 steps:\n",
    "    1. By abs_pcc: ignore fts with low pcc.\n",
    "    2. By take_this_many_top_fts: only fts with topmost pccs selected.'''\n",
    "    def filter_ftsIn_multiIndexed_df_by_pcc(self, df):\n",
    "        df[\"abs_pcc\"] = abs(df.index.get_level_values(\"pcc\"))\n",
    "        df = df.sort_values(by=[\"abs_pcc\"], ascending=False)\n",
    "        df = df[df[\"abs_pcc\"] >= self.pcc_lowerlimit_to_filter_dhss]  # filter by abs_pcc\n",
    "        df = df.drop(labels=[\"abs_pcc\"], axis=1)\n",
    "        if (df.shape[0] > self.take_this_many_top_fts > 0):\n",
    "            df = df[:self.take_this_many_top_fts]  # this df is sorted by abs_pcc (4 steps back)\n",
    "        return df\n",
    "\n",
    "    '''Get df_tfs. The csv_cn_tfs file is read fast.'''\n",
    "    def get_df_cn_tfs(self):\n",
    "        '''df_tfs will have following original columns:\n",
    "        TG TF zcores corr type species'''\n",
    "        df_cnTfs = pd.read_csv(self.csv_cn, sep=\",\", header=0)\n",
    "        df_cnTfs = df_cnTfs[df_cnTfs[\"TG\"] == self.gene_ofInterest]\n",
    "        df_cnTfs = df_cnTfs.drop_duplicates(subset=\"TF\", keep=\"first\")  # some TFs could be present in >1 row \n",
    "        df_cnTfs = df_cnTfs[[\"TF\", \"zscore\", \"corr\"]]\n",
    "        df_cnTfs.columns = [\"geneName\", \"zscore\", \"cn_corr\"]  # \"geneName\" will be used to merge with df_tfs later\n",
    "        return df_cnTfs.set_index('geneName')\n",
    "\n",
    "    def get_df_tfs(self, df_rnase):\n",
    "        '''df_tfs has \"geneName\", \"loc\", \"TAD_loc\", \"zscore\", \"cn_corr\" and \"pcc\" as index.\n",
    "        The cols are gexes in samples / cell types. The TFs (i.e. \"geneName\") are filtered\n",
    "        by self.filter_tfs_by argument (i.e. \"zscore\" or \"pearson_corr\") threshold and \n",
    "        subsequently by self.take_this_many_top_fts on the same argument.\n",
    "        '''\n",
    "        df_cnTfs = self.get_df_cn_tfs()  # has zscores and cn_corr as cols, and \"geneName\" (i.e. TFs) as indices\n",
    "        df_tfs = df_rnase.iloc[df_rnase.index.get_level_values(\"geneName\").isin(df_cnTfs.index)]\n",
    "        # assert df_cnTfs.shape[0] == df_tfs.shape[0] # Note: this need not be true.\n",
    "\n",
    "        '''First get the pcc values. Then merge the zscores and corr cols df and the pccs'''\n",
    "        pccs = []\n",
    "        for ix in range(0, df_tfs.shape[0]):  # note df_cnTfs has geneNames sorted as in df_tfs.\n",
    "            pccs.append(np.corrcoef(df_tfs.iloc[ix], self.goi)[0,1])\n",
    "\n",
    "        '''Merge df_cnTfs with df_tfs. Add zscore, cn_corr and pcc cols to the merged df'''\n",
    "        df_tfs = df_cnTfs.join(df_tfs, how='inner')\n",
    "        df_tfs[\"pcc\"] = pccs\n",
    "        df_tfs = df_tfs.set_index([\"zscore\", \"cn_corr\", \"pcc\"], append=True)\n",
    "\n",
    "        return df_tfs\n",
    "    \n",
    "    \n",
    "    '''Filter by zcore/pcc lower limit first, then filter again to get only top fts'''\n",
    "    def filter_tf_fts(self, df_tfs):\n",
    "        if (self.filter_tfs_by == \"zscore\"):  # zscores are all positive; sorting and filtering is not complicated.\n",
    "            df_tfs = df_tfs[df_tfs.index.get_level_values(\"zscore\") >= self.lowerlimit_to_filter_tfs]\n",
    "            if (df_tfs.shape[0] > self.take_this_many_top_fts > 0):  # self.take_this_many_top_fts is set to -1 if all fts are to be used \n",
    "                df_tfs = df_tfs.sort_index(axis=0, level=\"zscore\", ascending=False)[:self.take_this_many_top_fts]\n",
    "        else:\n",
    "            df_tfs = self.filter_ftsIn_multiIndexed_df_by_pcc(df_tfs)\n",
    "        return df_tfs\n",
    "    \n",
    "    \n",
    "    '''If random DHSs are to be selected, only select a random\n",
    "    collection of self.take_this_many_top_dhs_fts from the genome.'''\n",
    "    def get_random_roi_dhs_df(self):\n",
    "        df_dhss = pd.read_csv(self.csv_dhss, sep=\"\\t\", index_col=\"loc\")  # df_dhss is the original dhs with loc of chr:ss-es as index and sample values as cols across\n",
    "        rand_ints = sorted(random.sample(range(0, df_dhss.shape[0]), self.take_this_many_top_dhs_fts))  # sorted() will yield sorted list of dhss also\n",
    "        rand_locs = [df_dhss.index[x] for x in rand_ints]\n",
    "        df_dhss_random = df_dhss[df_dhss.index.isin(rand_locs)]\n",
    "        return df_dhss_random\n",
    "\n",
    "    def get_random_tfs_df(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do: Finish functions to get random TFs and DHSs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - EOF - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
