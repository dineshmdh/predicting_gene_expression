{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search\n",
    "\n",
    "Source: https://github.com/itdxer/neupy/blob/master/notebooks/Hyperparameter%20optimization%20for%20Neural%20Networks.ipynb\n",
    "and http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html#id14\n",
    "\n",
    "```python\n",
    "Hyperparams to train:\n",
    "1. lamda\n",
    "2. number of hidden layers\n",
    "3. number of hidden units\n",
    "3. starter learning rate\n",
    "5. use_sigmoid_h1\n",
    "6. use_sigmoid_h2```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-14 20:28:09,308: global_variables_final_for_git: INFO    : Setting up the DNase-seq dataframe and gene expression vector..\n",
      "2018-01-14 20:28:10,162: global_variables_final_for_git: ERROR   : The gene name is not found. Double check the name.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The gene name is not found. Double check the name?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dee4f73ad59f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mgv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobal_Vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputDir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# note this takes in new_output_dir as well in .py scripts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel_preparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Dinesh/Dropbox/Github/predicting_gex_with_nn_git/Functions/model_scripts/helper_scripts/global_variables_final_for_git.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, new_out_dir)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mdf_rnase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv_rnase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"geneName\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TAD_loc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gene_ofInterest_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_rnase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_log2_tpm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Dinesh/Dropbox/Github/predicting_gex_with_nn_git/Functions/model_scripts/helper_scripts/global_variables_final_for_git.py\u001b[0m in \u001b[0;36mget_gene_ofInterest_info\u001b[0;34m(self, df_rnase)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_gene_ofInterest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The gene name is not found. Double check the name.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The gene name is not found. Double check the name?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mgene_ofInterest_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_gene_ofInterest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgene_ofInterest_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The gene name is not found. Double check the name?"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path = sys.path[1:]\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"helper_scripts\"))  # pretending we are running main.py in jupyter\n",
    "\n",
    "from global_variables_final_for_git import Global_Vars\n",
    "from prep_for_model_for_git import Model_preparation\n",
    "import pandas as pd\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import fmin\n",
    "import HPO_helper\n",
    "from HPO_helper import uniform_int, loguniform_int, tpe_method, get_parameter_space_forHPO\n",
    "from tensorflow_model_for_git import Tensorflow_model\n",
    "\n",
    "start_time = time.time()\n",
    "if __name__==\"__main__\":\n",
    "    class Args(object):\n",
    "        def __init__(self):\n",
    "            self.gene = \"ARPP21\"\n",
    "            self.distance = 200\n",
    "            self.use_tad_info = True\n",
    "            self.pcc_lowerlimit_to_filter_dhss = 0.25\n",
    "            self.take_log2_tpm = True\n",
    "            self.filter_tfs_by = \"zscore\" # or \"pcc\"\n",
    "            self.lowerlimit_to_filter_tfs = 4.75\n",
    "            self.take_this_many_top_fts = 15  # all dhss/tfs will already be filtered by pcc(or zscore)\n",
    "            self.init_wts_type = \"corr\"\n",
    "            self.outputDir = \"/Users/Dinesh/Dropbox/Github/predicting_gex_with_nn_git/Output/testing/ARPP21\"\n",
    "            self.use_random_DHSs = False\n",
    "            self.use_random_TFs = False\n",
    "            self.max_iter = 500\n",
    "\n",
    "    args = Args()\n",
    "    gv = Global_Vars(args, args.outputDir)  # note this takes in new_output_dir as well in .py scripts\n",
    "    mp = Model_preparation(gv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Run HPO on differen train/test splits'''\n",
    "for test_idx in range(0, 19):\n",
    "    # test_idx = 5  # 5 corresponds to ES_deriv group\n",
    "    if (test_idx == 4): # corresponds to val_group of \"ENCODE2012\"\n",
    "        continue\n",
    "    start_time = time.time()\n",
    "    tm = Tensorflow_model(gv, mp, test_eid_group_index=test_idx)\n",
    "    trials = hyperopt.Trials()\n",
    "\n",
    "    best_params = hyperopt.fmin(\n",
    "        tm.train_tensorflow_nn,\n",
    "        trials=trials,\n",
    "        space=get_parameter_space_forHPO(tm.trainX),\n",
    "        algo=tpe_method,     # Set up TPE for hyperparameter optimization\n",
    "        max_evals=5,     # Maximum number of iterations. Basically it trains at most 200 networks before choose the best one.\n",
    "    )\n",
    "\n",
    "    med_pc_test_error = tm.plot_scatter_performance(trials, gv, index=None)\n",
    "    tm.logger.info(\"Test Group {}:{}, Median Test Percentage Error: {}, Best Params: {}\".format(\n",
    "            tm.test_eid_group_index, tm.test_eid_group,\n",
    "            round(med_pc_test_error, 4), best_params))\n",
    "\n",
    "    if (test_idx == 6): \n",
    "         break\n",
    "    del tm, trials, best_params\n",
    "    \n",
    "print(\"Total time taken: {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - EOF - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
