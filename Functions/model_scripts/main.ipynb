{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search\n",
    "\n",
    "Source: https://github.com/itdxer/neupy/blob/master/notebooks/Hyperparameter%20optimization%20for%20Neural%20Networks.ipynb\n",
    "and http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html#id14\n",
    "\n",
    "```python\n",
    "Hyperparams to train:\n",
    "1. lamda\n",
    "2. number of hidden layers\n",
    "3. number of hidden units\n",
    "3. starter learning rate\n",
    "5. use_sigmoid_h1\n",
    "6. use_sigmoid_h2```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path = sys.path[1:]\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"helper_scripts\"))  # pretending we are running main.py in jupyter\n",
    "\n",
    "import global_variables_final_for_git\n",
    "reload(global_variables_final_for_git)\n",
    "from global_variables_final_for_git import Global_Vars\n",
    "from prep_for_model_for_git import Model_preparation\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import fmin\n",
    "import HPO_helper\n",
    "reload(HPO_helper)\n",
    "from HPO_helper import uniform_int, loguniform_int, tpe_method, get_parameter_space_forHPO\n",
    "import tensorflow_model_for_git\n",
    "reload(tensorflow_model_for_git)\n",
    "from tensorflow_model_for_git import Tensorflow_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "class Args(object):\n",
    "    def __init__(self):\n",
    "        self.gene = \"TNNC2\"\n",
    "        self.distance = 150\n",
    "        self.use_tad_info = True\n",
    "        self.pcc_lowerlimit_to_filter_dhss = 0.2\n",
    "        self.filter_tfs_by = \"zscore\" # or \"pcc\"\n",
    "        self.lowerlimit_to_filter_tfs = 6\n",
    "        self.take_this_many_top_dhss = 6  # all dhss/tfs will already be filtered by pcc(or zscore)\n",
    "        self.take_this_many_top_tfs = 10\n",
    "        self.init_wts_type = \"corr\"\n",
    "        self.outputDir = \"/Users/Dinesh/Dropbox/Github/predicting_gex_with_nn_git/Output_new/\"+self.gene.upper()\n",
    "        self.use_random_DHSs = False\n",
    "        self.use_random_TFs = False \n",
    "        self.max_iter = 150\n",
    "        self.plot_all = True\n",
    "\n",
    "###test_idx = 17 # 2 to brain; 6 to ESC; 7 is epithelial; 8 is HSC and B; 12 is muscle; 5 is ES-derived\n",
    "start_time = time.time()\n",
    "args = Args()\n",
    "gv = Global_Vars(args, args.outputDir)  # note this takes in new_output_dir as well in .py scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input_data(gv):\n",
    "    plt.figure(figsize=(12, 21))\n",
    "    plt.subplot(1,3,1)\n",
    "    sns.heatmap(gv.df_dhss.transpose(),yticklabels=True)\n",
    "    plt.subplot(1,3,2)\n",
    "    sns.heatmap(gv.df_tfs.transpose(), yticklabels=False)\n",
    "    plt.subplot(1,3,3)\n",
    "    sns.heatmap(gv.goi.to_frame(), yticklabels=False)\n",
    "    plt.savefig(os.path.join(gv.outputDir, \"input_feats_and_goi.pdf\"))\n",
    "plot_input_data(gv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Run HPO on differen train/test splits'''\n",
    "mp = Model_preparation(gv)\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''After updates - what i had before'''\n",
    "\n",
    "tm.get_importance_scores(updates)\n",
    "\n",
    "to_log, plot_title = tm.get_log_info_to_save_after_retraining(trainY, updates, title_prefix=title_prefix)  # title prefix only has mode, test group, and testX.shape infos\n",
    "print(to_log)  # logger.info(to_log)\n",
    "plot_title = \"{};{}\".format(gv.gene_ofInterest, plot_title)\n",
    "tm.plot_performance_after_retraining(amode, gv, updates, trainY, plot_title=plot_title)\n",
    "\n",
    "del tm, trials, best_params, index\n",
    "del to_log, title_info, title_prefix, title_error_msg, title_suffix, plot_title\n",
    "del wts, layer_sizes, lamda, trainX, trainY, b1, g1, b2, g2, updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections as col\n",
    "import copy\n",
    "dict_ims = col.OrderedDict()  # {<feat_index>: [rmse]}  # typically this will only have one or few elements since running for lots of test groups take a long time\n",
    "\n",
    "for amode in [\"joint\"]: # [\"joint\"]: #, \"tfs\", \"dhss\"]:\n",
    "    for test_idx in range(1,2):\n",
    "        if (test_idx == 4):\n",
    "            continue\n",
    "        tm = Tensorflow_model(gv, mp, test_eid_group_index=test_idx, mode=amode)\n",
    "        trials = hyperopt.Trials()\n",
    "        best_params = hyperopt.fmin(tm.train_tensorflow_nn, trials=trials,\n",
    "                                    space=get_parameter_space_forHPO(tm.trainX),\n",
    "                                    algo=tpe_method, max_evals=8)\n",
    "\n",
    "        index = np.argmin(trials.losses())\n",
    "        to_log = tm.get_log_into_to_save(index, trials, best_params, mode=amode)\n",
    "        print(to_log) # logger.info(to_log)\n",
    "\n",
    "        title_info = re.split(\";best_params\", to_log)[0]  # \"title\" refers to plot_title\n",
    "        title_prefix, title_error_msg, title_suffix = re.split(\";median_pc_error|;PCC\", title_info)  # note title_prefix already has the \"mode\" info\n",
    "        title_info = title_prefix + \"\\nmed_pc_err\" + title_error_msg + \"\\nPCC\" + title_suffix\n",
    "        plot_title = \"{};{}\".format(gv.gene_ofInterest, title_info)\n",
    "        tm.plot_scatter_performance(amode, index, trials, gv, plot_title=plot_title)\n",
    "\n",
    "        # Now retrain using the validation set\n",
    "        starter_lr, use_sigmoid_h1, use_sigmoid_h2, use_sigmoid_yhat, wts, layer_sizes, lamda, trainX, trainY, b1, g1, b2, g2 = tm.get_params_from_best_trial(index, trials, best_params)  # nn_updates is the new dict, not the one in tf_model class\n",
    "        updates = tm.retrain_tensorflow_nn(starter_lr, use_sigmoid_h1, use_sigmoid_h2, use_sigmoid_yhat, wts, layer_sizes, lamda, trainX, trainY, b1, g1, b2, g2)\n",
    "        \n",
    "        # collect the rmses\n",
    "        X_ori = np.concatenate((trainX, tm.testX), axis=0)  # trainX = tm.trainX + tm.valX\n",
    "        Y_ori = np.concatenate((trainY, tm.testY), axis=0)  # this should not be imputed\n",
    "        r_ori = tm.get_rmse(updates, use_sigmoid_h1, use_sigmoid_h2, use_sigmoid_yhat, layer_sizes, lamda, X_=X_ori, Y_ori=Y_ori)\n",
    "        for i in range(0, X_ori.shape[1]):  # for all features\n",
    "            X_ = copy.deepcopy(X_ori)\n",
    "            X_[:,i] = 0  # mutate the feat column\n",
    "            r_ = tm.get_rmse(updates, use_sigmoid_h1, use_sigmoid_h2, use_sigmoid_yhat, layer_sizes, lamda, X_=X_, Y_ori=Y_ori)  # only X is mutated \n",
    "            if (i in dict_ims.keys()):\n",
    "                dict_ims[i].append(abs(r_ori - r_))\n",
    "            else:\n",
    "                dict_ims[i] = [abs(r_ori - r_)]\n",
    "            del X_\n",
    "            \n",
    "            # if feature index is ___: do perturbation in silico experiments\n",
    "        write_rmses(dict_ims)\n",
    "    \n",
    "        to_log, plot_title = tm.get_log_info_to_save_after_retraining(trainY, updates, title_prefix=title_prefix)  # title prefix only has mode, test group, and testX.shape infos\n",
    "        print(to_log)  # logger.info(to_log)\n",
    "        plot_title = \"{};{}\".format(gv.gene_ofInterest, plot_title)\n",
    "        tm.plot_performance_after_retraining(amode, gv, updates, trainY, plot_title=plot_title)\n",
    "\n",
    "        '''del tm, trials, best_params, index\n",
    "        del to_log, title_info, title_prefix, title_error_msg, title_suffix, plot_title\n",
    "        del wts, layer_sizes, lamda, trainX, trainY, b1, g1, b2, g2, updates'''\n",
    "    \n",
    "        print(\"done with mode:\", amode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_rmses(adict_ims):\n",
    "    '''Write the RMSEs (importance scores) corresponding to feature mutations in a file. \n",
    "    Arguments:\n",
    "    - adict_ims is the importance score dict, with a list of rmses for each feature index keys.\n",
    "    '''\n",
    "    handleIn = open(os.path.join(gv.outputDir, \"feat_importance_scores.txt\"), \"aw\")\n",
    "    for k,v in adict_ims.items():\n",
    "        for av in v: # for each rmse value corresponding to the feature\n",
    "            handleIn.write(\"{}:{}\".format(k,av))\n",
    "    handleIn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adict = dict_ims # from 8 to 11 inclusive (0 based indexing)\n",
    "for k,v in adict.items():\n",
    "    print(k,len(v), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(adict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the effect of increasing predictor signal to gene expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat = tm.get_yhat(updates, use_sigmoid_h1, use_sigmoid_h2, use_sigmoid_yhat, layer_sizes, lamda, X_=X_ori, Y_ori=Y_ori)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(yhat[0].flatten(), Y_ori.flatten())\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "plt.figure(figsize=(5,5))\n",
    "yhat = tm.get_yhat(updates, use_sigmoid_h1, use_sigmoid_h2, use_sigmoid_yhat, layer_sizes, lamda, X_=X_ori, Y_ori=Y_ori)\n",
    "plt.scatter(Y_ori.flatten(), yhat[0].flatten(), alpha=0.3)\n",
    "\n",
    "X_ = copy.deepcopy(tm.valX)\n",
    "yval_hat = tm.get_yhat(updates, use_sigmoid_h1, use_sigmoid_h2, use_sigmoid_yhat, layer_sizes, lamda, X_=X_, Y_ori=tm.valY)\n",
    "sns.regplot(tm.valY.flatten(), yval_hat[0].flatten(), color=\"salmon\")\n",
    "\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel(\"Real expression\")\n",
    "plt.ylabel(\"Predicted expression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip(tm.val_goi, yval_hat[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_index = 3 # feature index in X matrices\n",
    "max_fold = 5  # max fold increase\n",
    "\n",
    "index_hsmm = np.where(tm.valY.flatten() == tm.val_goi[\"E120_MUS.HSMM_ENCODE2012\"])[0][0]\n",
    "index_hsmmt = np.where(tm.valY.flatten() == tm.val_goi[\"E121_MUS.HSMMT_ENCODE2012\"])[0][0]\n",
    "index_brain = np.where(tm.valY.flatten() == tm.val_goi[\"E125_BRN.NHA_ENCODE2012\"])[0][0]\n",
    "index_blood = np.where(tm.valY.flatten() == tm.val_goi[\"E124_BLD.CD14.MONO_ENCODE2012\"])[0][0]\n",
    "\n",
    "for feat_index in [6,7,8]:\n",
    "    expn_in_hsmm = []\n",
    "    expn_in_hsmmt = []\n",
    "    expn_in_brain = []\n",
    "    expn_in_blood = []\n",
    "\n",
    "    for i in range(1, max_fold): # from 1x to 5x\n",
    "        X_ = copy.deepcopy(tm.valX)\n",
    "        X_[:,feat_index] *= i\n",
    "        yval_hat = tm.get_yhat(updates, use_sigmoid_h1, use_sigmoid_h2, use_sigmoid_yhat, layer_sizes, lamda, X_=X_, Y_ori=tm.valY)\n",
    "        expn_in_hsmm.append(yval_hat[0].flatten()[index_hsmm])\n",
    "        expn_in_hsmmt.append(yval_hat[0].flatten()[index_hsmmt])\n",
    "        expn_in_brain.append(yval_hat[0].flatten()[index_brain])\n",
    "        expn_in_blood.append(yval_hat[0].flatten()[index_blood])\n",
    "        print(expn_in_hsmm) \n",
    "        print(expn_in_hsmmt) \n",
    "\n",
    "    '''Plot the expn in cell line tracked'''\n",
    "    only_hsmmt = True\n",
    "    plt.plot(range(1,max_fold), expn_in_hsmmt, color=\"red\")\n",
    "    plt.axhline(y=tm.val_goi[index_hsmmt], color=\"red\", linestyle=\"--\", label=\"hsmmt\")\n",
    "\n",
    "    if (not only_hsmmt):\n",
    "        plt.plot(range(1,max_fold), expn_in_hsmm, color=\"orange\")\n",
    "        plt.plot(range(1,max_fold), expn_in_brain, color=\"blue\")\n",
    "        plt.plot(range(1,max_fold), expn_in_blood, color=\"green\")\n",
    "        plt.axhline(y=tm.val_goi[index_hsmm], color=\"orange\", linestyle=\"--\", label=\"hsmm\")\n",
    "        plt.axhline(y=tm.val_goi[index_brain], color=\"blue\", linestyle=\"--\", label=\"brain\")\n",
    "        plt.axhline(y=tm.val_goi[index_blood], color=\"green\", linestyle=\"--\", label=\"blood\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Fold increase\")\n",
    "    plt.ylabel(\"Normalized predicted expression\")\n",
    "\n",
    "    if (only_hsmmt):\n",
    "        plt.savefig(gv.outputDir+\"/zerobased_featIndex{}_overexpn_for_tnnc2_in_hsmmtOnly.pdf\".format(feat_index))\n",
    "    else:\n",
    "        plt.savefig(gv.outputDir+\"/zerobased_featIndex{}_overexpn_for_tnnc2.pdf\".format(feat_index))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#saving upto idx=7 (0-based) \n",
    "adict_to7 = dict_ims\n",
    "for k,v in adict_to7.items():\n",
    "    print(k,len(v), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###adict = {\"a\":[1,2,3], 1:[11,21,31]}\n",
    "df = pd.DataFrame.from_dict(adict, orient='columns', dtype=None)\n",
    "df_m = pd.melt(df, id_vars=[\"index\"], value_vars=df.columns.tolist())  \n",
    "#note: first 2 elements in columns list are \"level_0\" and index\" now \n",
    "df_m.columns = [\"index\", \"Feature\", \"Importance Score\"]\n",
    "df_m = df_m[[\"Feature\", \"Importance Score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.boxplot(x=\"Feature\", y=\"Importance Score\", data=df_m)\n",
    "plt.xticks(rotation=85)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - EOF - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "# SINCE LAST COMMIT\n",
    "\n",
    "'''Run HPO on differen train/test splits'''\n",
    "tm = Tensorflow_model(gv, mp, test_eid_group_index=test_idx, mode = \"joint\")  # mode should be one of \"dhss\", \"tfs\", \"joint\"\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.heatmap(tm.trainX, vmin=0, vmax=1)\n",
    "plt.title('trainX')\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.heatmap(tm.trainY, vmin=0, vmax=1)\n",
    "plt.title('trainY')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.heatmap(tm.testX, vmin=0, vmax=1)\n",
    "plt.title('testX')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.heatmap(tm.testY, vmin=0, vmax=1)\n",
    "plt.title('testY')\n",
    "plt.suptitle(\"{}, test_idx:{}\".format(gv.gene_ofInterest, test_idx))\n",
    "\n",
    "'''Now train and search for HPO'''\n",
    "trials = hyperopt.Trials()\n",
    "best_params = hyperopt.fmin(tm.train_tensorflow_nn, trials=trials,\n",
    "                            space=get_parameter_space_forHPO(tm.trainX),\n",
    "                            algo=tpe_method, max_evals=10)\n",
    "index = np.argmin(trials.losses())\n",
    "to_log = tm.get_log_into_to_save(index, trials, best_params)\n",
    "plot_title = re.split(\";best_params\", to_log)[0]\n",
    "plot_title_prefix, plot_title_error_msg, plot_title_suffix = re.split(\";median_pc_error|;PCC\", plot_title)\n",
    "plot_title = plot_title_prefix + \"\\nmed_pc_err\" + plot_title_error_msg + \"\\nPCC\" + plot_title_suffix\n",
    "tm.plot_scatter_performance(trials, gv, gv.gene_ofInterest + \";\" + plot_title)\n",
    "\n",
    "print(\"Total time taken: {}\".format(time.time() - start_time))\n",
    "\n",
    "index = np.argmin(trials.losses())\n",
    "plt.plot(trials.results[index][\"train_loss\"], color=\"salmon\")\n",
    "plt.plot(trials.results[index][\"val_loss\"], color=\"mediumvioletred\")\n",
    "\n",
    "index = np.argmin(trials.losses())\n",
    "wts, layer_sizes, lamda, trainX, trainY, nn_updates, b1, g1, b2, g2 = tm.get_params_from_best_trial(index, trials, best_params)\n",
    "updates = tm.retrain_tensorflow_nn(wts, layer_sizes, lamda, trainX, trainY, nn_updates, b1, g1, b2, g2)\n",
    "tm.plot_performance_after_retraining(gv, updates, trainY, title_prefix=plot_title_prefix)  # need to pass in the title_prefix\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting six1 vs tnnc2 gene expn\n",
    "X_ori = np.concatenate((trainX, tm.testX), axis=0)  # trainX = tm.trainX + tm.valX\n",
    "Y_ori = np.concatenate((trainY, tm.testY), axis=0)  # this should not be imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_ori[:,6], Y_ori.flatten())\n",
    "plt.title(\"{}\".format(np.corrcoef(np.array(X_ori[:,6]), np.array(Y_ori.flatten()))))\n",
    "plt.xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_ori[:,7], Y_ori.flatten())\n",
    "plt.title(\"{}\".format(np.corrcoef(np.array(X_ori[:,7]), np.array(Y_ori.flatten()))))\n",
    "plt.xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_ori[:,8], Y_ori.flatten())\n",
    "plt.title(\"{}\".format(np.corrcoef(np.array(X_ori[:,8]), np.array(Y_ori.flatten()))))\n",
    "plt.xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_ori[:,3], Y_ori.flatten())\n",
    "plt.title(\"{}\".format(np.corrcoef(np.array(X_ori[:,3]), np.array(Y_ori.flatten()))))\n",
    "plt.xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_ori[:,12], Y_ori.flatten())\n",
    "plt.title(\"{}\".format(np.corrcoef(np.array(X_ori[:,12]), np.array(Y_ori.flatten()))))\n",
    "plt.xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_ori[:,10], Y_ori.flatten())\n",
    "plt.title(\"{}\".format(np.corrcoef(np.array(X_ori[:,10]), np.array(Y_ori.flatten()))))\n",
    "plt.xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
